{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5168700646087581,
  "eval_steps": 200,
  "global_step": 1800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002871500358937545,
      "grad_norm": 19.299386978149414,
      "learning_rate": 1.25e-05,
      "loss": 18.7848,
      "step": 10
    },
    {
      "epoch": 0.00574300071787509,
      "grad_norm": 31.180194854736328,
      "learning_rate": 2.6388888888888892e-05,
      "loss": 15.0444,
      "step": 20
    },
    {
      "epoch": 0.008614501076812634,
      "grad_norm": 3.088996648788452,
      "learning_rate": 4.027777777777778e-05,
      "loss": 9.1087,
      "step": 30
    },
    {
      "epoch": 0.01148600143575018,
      "grad_norm": 0.43901970982551575,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 7.8626,
      "step": 40
    },
    {
      "epoch": 0.014357501794687724,
      "grad_norm": 0.41389110684394836,
      "learning_rate": 6.805555555555556e-05,
      "loss": 7.5452,
      "step": 50
    },
    {
      "epoch": 0.01722900215362527,
      "grad_norm": 0.2217784970998764,
      "learning_rate": 8.194444444444445e-05,
      "loss": 7.4652,
      "step": 60
    },
    {
      "epoch": 0.020100502512562814,
      "grad_norm": 0.12275433540344238,
      "learning_rate": 9.583333333333334e-05,
      "loss": 7.4447,
      "step": 70
    },
    {
      "epoch": 0.02297200287150036,
      "grad_norm": 0.13979996740818024,
      "learning_rate": 9.969931271477664e-05,
      "loss": 7.431,
      "step": 80
    },
    {
      "epoch": 0.025843503230437905,
      "grad_norm": 0.4550146758556366,
      "learning_rate": 9.926975945017183e-05,
      "loss": 7.4385,
      "step": 90
    },
    {
      "epoch": 0.028715003589375447,
      "grad_norm": 1.0453448295593262,
      "learning_rate": 9.884020618556701e-05,
      "loss": 7.4318,
      "step": 100
    },
    {
      "epoch": 0.03158650394831299,
      "grad_norm": 0.8081639409065247,
      "learning_rate": 9.84106529209622e-05,
      "loss": 7.4329,
      "step": 110
    },
    {
      "epoch": 0.03445800430725054,
      "grad_norm": 0.25886791944503784,
      "learning_rate": 9.79810996563574e-05,
      "loss": 7.428,
      "step": 120
    },
    {
      "epoch": 0.03732950466618808,
      "grad_norm": 0.4174894690513611,
      "learning_rate": 9.755154639175258e-05,
      "loss": 7.4235,
      "step": 130
    },
    {
      "epoch": 0.04020100502512563,
      "grad_norm": 0.1470590978860855,
      "learning_rate": 9.712199312714777e-05,
      "loss": 7.4268,
      "step": 140
    },
    {
      "epoch": 0.043072505384063174,
      "grad_norm": 0.12781842052936554,
      "learning_rate": 9.669243986254296e-05,
      "loss": 7.4234,
      "step": 150
    },
    {
      "epoch": 0.04594400574300072,
      "grad_norm": 0.8904435038566589,
      "learning_rate": 9.626288659793815e-05,
      "loss": 7.4245,
      "step": 160
    },
    {
      "epoch": 0.048815506101938265,
      "grad_norm": 1.0419000387191772,
      "learning_rate": 9.583333333333334e-05,
      "loss": 7.4223,
      "step": 170
    },
    {
      "epoch": 0.05168700646087581,
      "grad_norm": 1.2327383756637573,
      "learning_rate": 9.540378006872853e-05,
      "loss": 7.4302,
      "step": 180
    },
    {
      "epoch": 0.054558506819813356,
      "grad_norm": 0.23289945721626282,
      "learning_rate": 9.497422680412372e-05,
      "loss": 7.4229,
      "step": 190
    },
    {
      "epoch": 0.057430007178750894,
      "grad_norm": 0.1853548288345337,
      "learning_rate": 9.45446735395189e-05,
      "loss": 7.4301,
      "step": 200
    },
    {
      "epoch": 0.057430007178750894,
      "eval_loss": 7.416553974151611,
      "eval_runtime": 300.395,
      "eval_samples_per_second": 0.666,
      "eval_steps_per_second": 0.166,
      "step": 200
    },
    {
      "epoch": 0.06030150753768844,
      "grad_norm": 0.9728057980537415,
      "learning_rate": 9.41151202749141e-05,
      "loss": 7.4184,
      "step": 210
    },
    {
      "epoch": 0.06317300789662599,
      "grad_norm": 0.6273782849311829,
      "learning_rate": 9.368556701030928e-05,
      "loss": 7.4323,
      "step": 220
    },
    {
      "epoch": 0.06604450825556353,
      "grad_norm": 0.38446080684661865,
      "learning_rate": 9.325601374570447e-05,
      "loss": 7.4237,
      "step": 230
    },
    {
      "epoch": 0.06891600861450108,
      "grad_norm": 0.25884440541267395,
      "learning_rate": 9.282646048109966e-05,
      "loss": 7.4122,
      "step": 240
    },
    {
      "epoch": 0.07178750897343862,
      "grad_norm": 0.24638329446315765,
      "learning_rate": 9.239690721649485e-05,
      "loss": 7.4217,
      "step": 250
    },
    {
      "epoch": 0.07465900933237617,
      "grad_norm": 0.651009202003479,
      "learning_rate": 9.196735395189004e-05,
      "loss": 7.4149,
      "step": 260
    },
    {
      "epoch": 0.07753050969131371,
      "grad_norm": 0.3427412211894989,
      "learning_rate": 9.153780068728522e-05,
      "loss": 7.4221,
      "step": 270
    },
    {
      "epoch": 0.08040201005025126,
      "grad_norm": 0.14131814241409302,
      "learning_rate": 9.110824742268042e-05,
      "loss": 7.4103,
      "step": 280
    },
    {
      "epoch": 0.0832735104091888,
      "grad_norm": 0.17234289646148682,
      "learning_rate": 9.06786941580756e-05,
      "loss": 7.4236,
      "step": 290
    },
    {
      "epoch": 0.08614501076812635,
      "grad_norm": 0.2196744978427887,
      "learning_rate": 9.02491408934708e-05,
      "loss": 7.423,
      "step": 300
    },
    {
      "epoch": 0.0890165111270639,
      "grad_norm": 0.8797856569290161,
      "learning_rate": 8.981958762886599e-05,
      "loss": 7.4159,
      "step": 310
    },
    {
      "epoch": 0.09188801148600144,
      "grad_norm": 0.40359458327293396,
      "learning_rate": 8.939003436426118e-05,
      "loss": 7.4192,
      "step": 320
    },
    {
      "epoch": 0.09475951184493898,
      "grad_norm": 0.3920519948005676,
      "learning_rate": 8.896048109965636e-05,
      "loss": 7.4314,
      "step": 330
    },
    {
      "epoch": 0.09763101220387653,
      "grad_norm": 0.2124243974685669,
      "learning_rate": 8.853092783505154e-05,
      "loss": 7.4167,
      "step": 340
    },
    {
      "epoch": 0.10050251256281408,
      "grad_norm": 0.4764740467071533,
      "learning_rate": 8.810137457044674e-05,
      "loss": 7.4152,
      "step": 350
    },
    {
      "epoch": 0.10337401292175162,
      "grad_norm": 0.15757091343402863,
      "learning_rate": 8.767182130584193e-05,
      "loss": 7.426,
      "step": 360
    },
    {
      "epoch": 0.10624551328068917,
      "grad_norm": 0.7916356921195984,
      "learning_rate": 8.724226804123712e-05,
      "loss": 7.4256,
      "step": 370
    },
    {
      "epoch": 0.10911701363962671,
      "grad_norm": 0.35498058795928955,
      "learning_rate": 8.681271477663231e-05,
      "loss": 7.4161,
      "step": 380
    },
    {
      "epoch": 0.11198851399856424,
      "grad_norm": 0.09758836776018143,
      "learning_rate": 8.63831615120275e-05,
      "loss": 7.4192,
      "step": 390
    },
    {
      "epoch": 0.11486001435750179,
      "grad_norm": 0.22871923446655273,
      "learning_rate": 8.595360824742269e-05,
      "loss": 7.4234,
      "step": 400
    },
    {
      "epoch": 0.11486001435750179,
      "eval_loss": 7.414809703826904,
      "eval_runtime": 297.1577,
      "eval_samples_per_second": 0.673,
      "eval_steps_per_second": 0.168,
      "step": 400
    },
    {
      "epoch": 0.11773151471643933,
      "grad_norm": 0.4145568907260895,
      "learning_rate": 8.552405498281788e-05,
      "loss": 7.4245,
      "step": 410
    },
    {
      "epoch": 0.12060301507537688,
      "grad_norm": 0.17028312385082245,
      "learning_rate": 8.509450171821306e-05,
      "loss": 7.4085,
      "step": 420
    },
    {
      "epoch": 0.12347451543431442,
      "grad_norm": 0.1981292963027954,
      "learning_rate": 8.466494845360826e-05,
      "loss": 7.4135,
      "step": 430
    },
    {
      "epoch": 0.12634601579325197,
      "grad_norm": 0.3585139513015747,
      "learning_rate": 8.423539518900344e-05,
      "loss": 7.4172,
      "step": 440
    },
    {
      "epoch": 0.12921751615218952,
      "grad_norm": 0.14827626943588257,
      "learning_rate": 8.380584192439863e-05,
      "loss": 7.4189,
      "step": 450
    },
    {
      "epoch": 0.13208901651112706,
      "grad_norm": 0.5686542987823486,
      "learning_rate": 8.337628865979382e-05,
      "loss": 7.4142,
      "step": 460
    },
    {
      "epoch": 0.1349605168700646,
      "grad_norm": 0.12375091016292572,
      "learning_rate": 8.294673539518901e-05,
      "loss": 7.4239,
      "step": 470
    },
    {
      "epoch": 0.13783201722900215,
      "grad_norm": 0.6752490997314453,
      "learning_rate": 8.25171821305842e-05,
      "loss": 7.4162,
      "step": 480
    },
    {
      "epoch": 0.1407035175879397,
      "grad_norm": 0.49080103635787964,
      "learning_rate": 8.208762886597938e-05,
      "loss": 7.4123,
      "step": 490
    },
    {
      "epoch": 0.14357501794687724,
      "grad_norm": 0.16628387570381165,
      "learning_rate": 8.165807560137458e-05,
      "loss": 7.4123,
      "step": 500
    },
    {
      "epoch": 0.1464465183058148,
      "grad_norm": 0.3048883080482483,
      "learning_rate": 8.122852233676976e-05,
      "loss": 7.4189,
      "step": 510
    },
    {
      "epoch": 0.14931801866475233,
      "grad_norm": 0.24200497567653656,
      "learning_rate": 8.079896907216496e-05,
      "loss": 7.4143,
      "step": 520
    },
    {
      "epoch": 0.15218951902368988,
      "grad_norm": 0.22520390152931213,
      "learning_rate": 8.036941580756014e-05,
      "loss": 7.4207,
      "step": 530
    },
    {
      "epoch": 0.15506101938262742,
      "grad_norm": 0.29051706194877625,
      "learning_rate": 7.993986254295534e-05,
      "loss": 7.4241,
      "step": 540
    },
    {
      "epoch": 0.15793251974156497,
      "grad_norm": 0.15253128111362457,
      "learning_rate": 7.951030927835052e-05,
      "loss": 7.4236,
      "step": 550
    },
    {
      "epoch": 0.16080402010050251,
      "grad_norm": 0.13253384828567505,
      "learning_rate": 7.90807560137457e-05,
      "loss": 7.421,
      "step": 560
    },
    {
      "epoch": 0.16367552045944006,
      "grad_norm": 0.1319577842950821,
      "learning_rate": 7.86512027491409e-05,
      "loss": 7.4194,
      "step": 570
    },
    {
      "epoch": 0.1665470208183776,
      "grad_norm": 0.2961868643760681,
      "learning_rate": 7.822164948453608e-05,
      "loss": 7.4162,
      "step": 580
    },
    {
      "epoch": 0.16941852117731515,
      "grad_norm": 0.24857735633850098,
      "learning_rate": 7.779209621993128e-05,
      "loss": 7.4103,
      "step": 590
    },
    {
      "epoch": 0.1722900215362527,
      "grad_norm": 0.9172337055206299,
      "learning_rate": 7.736254295532646e-05,
      "loss": 7.421,
      "step": 600
    },
    {
      "epoch": 0.1722900215362527,
      "eval_loss": 7.413118362426758,
      "eval_runtime": 304.357,
      "eval_samples_per_second": 0.657,
      "eval_steps_per_second": 0.164,
      "step": 600
    },
    {
      "epoch": 0.17516152189519024,
      "grad_norm": 0.11678395420312881,
      "learning_rate": 7.693298969072166e-05,
      "loss": 7.4216,
      "step": 610
    },
    {
      "epoch": 0.1780330222541278,
      "grad_norm": 0.24319936335086823,
      "learning_rate": 7.650343642611684e-05,
      "loss": 7.42,
      "step": 620
    },
    {
      "epoch": 0.18090452261306533,
      "grad_norm": 0.3057383596897125,
      "learning_rate": 7.607388316151202e-05,
      "loss": 7.4191,
      "step": 630
    },
    {
      "epoch": 0.18377602297200288,
      "grad_norm": 0.17984050512313843,
      "learning_rate": 7.564432989690722e-05,
      "loss": 7.4215,
      "step": 640
    },
    {
      "epoch": 0.18664752333094042,
      "grad_norm": 0.6050342321395874,
      "learning_rate": 7.52147766323024e-05,
      "loss": 7.4171,
      "step": 650
    },
    {
      "epoch": 0.18951902368987797,
      "grad_norm": 0.14228121936321259,
      "learning_rate": 7.47852233676976e-05,
      "loss": 7.4165,
      "step": 660
    },
    {
      "epoch": 0.19239052404881551,
      "grad_norm": 0.311612993478775,
      "learning_rate": 7.43556701030928e-05,
      "loss": 7.4169,
      "step": 670
    },
    {
      "epoch": 0.19526202440775306,
      "grad_norm": 0.2533014118671417,
      "learning_rate": 7.392611683848798e-05,
      "loss": 7.4145,
      "step": 680
    },
    {
      "epoch": 0.1981335247666906,
      "grad_norm": 0.16553328931331635,
      "learning_rate": 7.349656357388317e-05,
      "loss": 7.4125,
      "step": 690
    },
    {
      "epoch": 0.20100502512562815,
      "grad_norm": 0.166669562458992,
      "learning_rate": 7.306701030927834e-05,
      "loss": 7.4111,
      "step": 700
    },
    {
      "epoch": 0.2038765254845657,
      "grad_norm": 0.1432546228170395,
      "learning_rate": 7.263745704467354e-05,
      "loss": 7.4112,
      "step": 710
    },
    {
      "epoch": 0.20674802584350324,
      "grad_norm": 0.12523597478866577,
      "learning_rate": 7.220790378006874e-05,
      "loss": 7.4014,
      "step": 720
    },
    {
      "epoch": 0.2096195262024408,
      "grad_norm": 0.20523841679096222,
      "learning_rate": 7.177835051546392e-05,
      "loss": 7.4229,
      "step": 730
    },
    {
      "epoch": 0.21249102656137833,
      "grad_norm": 0.209231898188591,
      "learning_rate": 7.134879725085912e-05,
      "loss": 7.4083,
      "step": 740
    },
    {
      "epoch": 0.21536252692031588,
      "grad_norm": 0.17313122749328613,
      "learning_rate": 7.09192439862543e-05,
      "loss": 7.4123,
      "step": 750
    },
    {
      "epoch": 0.21823402727925342,
      "grad_norm": 0.1779385507106781,
      "learning_rate": 7.04896907216495e-05,
      "loss": 7.4293,
      "step": 760
    },
    {
      "epoch": 0.22110552763819097,
      "grad_norm": 0.4791349768638611,
      "learning_rate": 7.006013745704468e-05,
      "loss": 7.413,
      "step": 770
    },
    {
      "epoch": 0.22397702799712849,
      "grad_norm": 0.10434797406196594,
      "learning_rate": 6.963058419243986e-05,
      "loss": 7.421,
      "step": 780
    },
    {
      "epoch": 0.22684852835606603,
      "grad_norm": 0.15709812939167023,
      "learning_rate": 6.920103092783506e-05,
      "loss": 7.4212,
      "step": 790
    },
    {
      "epoch": 0.22972002871500358,
      "grad_norm": 0.1466742306947708,
      "learning_rate": 6.877147766323024e-05,
      "loss": 7.4272,
      "step": 800
    },
    {
      "epoch": 0.22972002871500358,
      "eval_loss": 7.411359786987305,
      "eval_runtime": 296.6225,
      "eval_samples_per_second": 0.674,
      "eval_steps_per_second": 0.169,
      "step": 800
    },
    {
      "epoch": 0.23259152907394112,
      "grad_norm": 0.10464584082365036,
      "learning_rate": 6.834192439862544e-05,
      "loss": 7.4206,
      "step": 810
    },
    {
      "epoch": 0.23546302943287867,
      "grad_norm": 0.23191790282726288,
      "learning_rate": 6.791237113402062e-05,
      "loss": 7.4106,
      "step": 820
    },
    {
      "epoch": 0.2383345297918162,
      "grad_norm": 0.21177160739898682,
      "learning_rate": 6.748281786941582e-05,
      "loss": 7.417,
      "step": 830
    },
    {
      "epoch": 0.24120603015075376,
      "grad_norm": 0.22082015872001648,
      "learning_rate": 6.7053264604811e-05,
      "loss": 7.409,
      "step": 840
    },
    {
      "epoch": 0.2440775305096913,
      "grad_norm": 0.1850566416978836,
      "learning_rate": 6.662371134020618e-05,
      "loss": 7.4109,
      "step": 850
    },
    {
      "epoch": 0.24694903086862885,
      "grad_norm": 0.1286623179912567,
      "learning_rate": 6.619415807560138e-05,
      "loss": 7.4075,
      "step": 860
    },
    {
      "epoch": 0.2498205312275664,
      "grad_norm": 0.10849579423666,
      "learning_rate": 6.576460481099656e-05,
      "loss": 7.4094,
      "step": 870
    },
    {
      "epoch": 0.25269203158650394,
      "grad_norm": 0.23772946000099182,
      "learning_rate": 6.533505154639176e-05,
      "loss": 7.4119,
      "step": 880
    },
    {
      "epoch": 0.2555635319454415,
      "grad_norm": 0.20665475726127625,
      "learning_rate": 6.490549828178694e-05,
      "loss": 7.4131,
      "step": 890
    },
    {
      "epoch": 0.25843503230437903,
      "grad_norm": 0.09684132039546967,
      "learning_rate": 6.447594501718214e-05,
      "loss": 7.4258,
      "step": 900
    },
    {
      "epoch": 0.2613065326633166,
      "grad_norm": 0.19618305563926697,
      "learning_rate": 6.404639175257732e-05,
      "loss": 7.4166,
      "step": 910
    },
    {
      "epoch": 0.2641780330222541,
      "grad_norm": 0.07911670953035355,
      "learning_rate": 6.36168384879725e-05,
      "loss": 7.412,
      "step": 920
    },
    {
      "epoch": 0.2670495333811917,
      "grad_norm": 0.16018247604370117,
      "learning_rate": 6.31872852233677e-05,
      "loss": 7.4194,
      "step": 930
    },
    {
      "epoch": 0.2699210337401292,
      "grad_norm": 0.12501950562000275,
      "learning_rate": 6.275773195876288e-05,
      "loss": 7.4183,
      "step": 940
    },
    {
      "epoch": 0.2727925340990668,
      "grad_norm": 0.11856663972139359,
      "learning_rate": 6.232817869415808e-05,
      "loss": 7.4124,
      "step": 950
    },
    {
      "epoch": 0.2756640344580043,
      "grad_norm": 0.23900173604488373,
      "learning_rate": 6.189862542955328e-05,
      "loss": 7.4185,
      "step": 960
    },
    {
      "epoch": 0.2785355348169419,
      "grad_norm": 0.17644673585891724,
      "learning_rate": 6.146907216494846e-05,
      "loss": 7.4112,
      "step": 970
    },
    {
      "epoch": 0.2814070351758794,
      "grad_norm": 0.13731905817985535,
      "learning_rate": 6.103951890034366e-05,
      "loss": 7.4143,
      "step": 980
    },
    {
      "epoch": 0.28427853553481697,
      "grad_norm": 0.20555946230888367,
      "learning_rate": 6.060996563573883e-05,
      "loss": 7.4154,
      "step": 990
    },
    {
      "epoch": 0.2871500358937545,
      "grad_norm": 0.1386118233203888,
      "learning_rate": 6.018041237113402e-05,
      "loss": 7.4137,
      "step": 1000
    },
    {
      "epoch": 0.2871500358937545,
      "eval_loss": 7.412127494812012,
      "eval_runtime": 297.0577,
      "eval_samples_per_second": 0.673,
      "eval_steps_per_second": 0.168,
      "step": 1000
    },
    {
      "epoch": 0.29002153625269206,
      "grad_norm": 0.10020392388105392,
      "learning_rate": 5.975085910652921e-05,
      "loss": 7.4159,
      "step": 1010
    },
    {
      "epoch": 0.2928930366116296,
      "grad_norm": 0.1219654306769371,
      "learning_rate": 5.93213058419244e-05,
      "loss": 7.4124,
      "step": 1020
    },
    {
      "epoch": 0.29576453697056715,
      "grad_norm": 0.09831806272268295,
      "learning_rate": 5.889175257731959e-05,
      "loss": 7.4234,
      "step": 1030
    },
    {
      "epoch": 0.29863603732950467,
      "grad_norm": 0.25116121768951416,
      "learning_rate": 5.846219931271478e-05,
      "loss": 7.4148,
      "step": 1040
    },
    {
      "epoch": 0.3015075376884422,
      "grad_norm": 0.24279232323169708,
      "learning_rate": 5.803264604810997e-05,
      "loss": 7.4219,
      "step": 1050
    },
    {
      "epoch": 0.30437903804737976,
      "grad_norm": 0.1426064521074295,
      "learning_rate": 5.760309278350515e-05,
      "loss": 7.4214,
      "step": 1060
    },
    {
      "epoch": 0.3072505384063173,
      "grad_norm": 0.26172178983688354,
      "learning_rate": 5.717353951890034e-05,
      "loss": 7.4238,
      "step": 1070
    },
    {
      "epoch": 0.31012203876525485,
      "grad_norm": 0.11691594123840332,
      "learning_rate": 5.674398625429553e-05,
      "loss": 7.4195,
      "step": 1080
    },
    {
      "epoch": 0.31299353912419237,
      "grad_norm": 0.1238287165760994,
      "learning_rate": 5.631443298969072e-05,
      "loss": 7.4099,
      "step": 1090
    },
    {
      "epoch": 0.31586503948312994,
      "grad_norm": 0.195744127035141,
      "learning_rate": 5.588487972508591e-05,
      "loss": 7.4195,
      "step": 1100
    },
    {
      "epoch": 0.31873653984206746,
      "grad_norm": 0.17060984671115875,
      "learning_rate": 5.54553264604811e-05,
      "loss": 7.4154,
      "step": 1110
    },
    {
      "epoch": 0.32160804020100503,
      "grad_norm": 0.1896209567785263,
      "learning_rate": 5.50257731958763e-05,
      "loss": 7.4169,
      "step": 1120
    },
    {
      "epoch": 0.32447954055994255,
      "grad_norm": 0.19428136944770813,
      "learning_rate": 5.4596219931271474e-05,
      "loss": 7.4187,
      "step": 1130
    },
    {
      "epoch": 0.3273510409188801,
      "grad_norm": 0.2838655412197113,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 7.4125,
      "step": 1140
    },
    {
      "epoch": 0.33022254127781764,
      "grad_norm": 0.17470555007457733,
      "learning_rate": 5.3737113402061854e-05,
      "loss": 7.4111,
      "step": 1150
    },
    {
      "epoch": 0.3330940416367552,
      "grad_norm": 0.17336566746234894,
      "learning_rate": 5.3307560137457044e-05,
      "loss": 7.4175,
      "step": 1160
    },
    {
      "epoch": 0.33596554199569273,
      "grad_norm": 0.7727344632148743,
      "learning_rate": 5.287800687285224e-05,
      "loss": 7.408,
      "step": 1170
    },
    {
      "epoch": 0.3388370423546303,
      "grad_norm": 0.14373576641082764,
      "learning_rate": 5.244845360824743e-05,
      "loss": 7.4139,
      "step": 1180
    },
    {
      "epoch": 0.3417085427135678,
      "grad_norm": 0.1652340143918991,
      "learning_rate": 5.201890034364262e-05,
      "loss": 7.4114,
      "step": 1190
    },
    {
      "epoch": 0.3445800430725054,
      "grad_norm": 0.17946241796016693,
      "learning_rate": 5.158934707903781e-05,
      "loss": 7.4197,
      "step": 1200
    },
    {
      "epoch": 0.3445800430725054,
      "eval_loss": 7.4089035987854,
      "eval_runtime": 296.7337,
      "eval_samples_per_second": 0.674,
      "eval_steps_per_second": 0.169,
      "step": 1200
    },
    {
      "epoch": 0.3474515434314429,
      "grad_norm": 0.19129379093647003,
      "learning_rate": 5.1159793814432985e-05,
      "loss": 7.4237,
      "step": 1210
    },
    {
      "epoch": 0.3503230437903805,
      "grad_norm": 0.1245657354593277,
      "learning_rate": 5.073024054982818e-05,
      "loss": 7.4184,
      "step": 1220
    },
    {
      "epoch": 0.353194544149318,
      "grad_norm": 0.08351755887269974,
      "learning_rate": 5.030068728522337e-05,
      "loss": 7.4145,
      "step": 1230
    },
    {
      "epoch": 0.3560660445082556,
      "grad_norm": 0.1237454041838646,
      "learning_rate": 4.987113402061856e-05,
      "loss": 7.4158,
      "step": 1240
    },
    {
      "epoch": 0.3589375448671931,
      "grad_norm": 1.562546968460083,
      "learning_rate": 4.944158075601375e-05,
      "loss": 7.4209,
      "step": 1250
    },
    {
      "epoch": 0.36180904522613067,
      "grad_norm": 0.15964901447296143,
      "learning_rate": 4.9012027491408934e-05,
      "loss": 7.415,
      "step": 1260
    },
    {
      "epoch": 0.3646805455850682,
      "grad_norm": 0.9385911822319031,
      "learning_rate": 4.8582474226804124e-05,
      "loss": 7.4159,
      "step": 1270
    },
    {
      "epoch": 0.36755204594400576,
      "grad_norm": 0.13115504384040833,
      "learning_rate": 4.8152920962199313e-05,
      "loss": 7.415,
      "step": 1280
    },
    {
      "epoch": 0.3704235463029433,
      "grad_norm": 0.09988327324390411,
      "learning_rate": 4.772336769759451e-05,
      "loss": 7.4099,
      "step": 1290
    },
    {
      "epoch": 0.37329504666188085,
      "grad_norm": 0.21867281198501587,
      "learning_rate": 4.729381443298969e-05,
      "loss": 7.4165,
      "step": 1300
    },
    {
      "epoch": 0.37616654702081836,
      "grad_norm": 0.14498284459114075,
      "learning_rate": 4.686426116838488e-05,
      "loss": 7.4126,
      "step": 1310
    },
    {
      "epoch": 0.37903804737975594,
      "grad_norm": 0.19441170990467072,
      "learning_rate": 4.643470790378007e-05,
      "loss": 7.4178,
      "step": 1320
    },
    {
      "epoch": 0.38190954773869346,
      "grad_norm": 0.23544034361839294,
      "learning_rate": 4.6005154639175255e-05,
      "loss": 7.4152,
      "step": 1330
    },
    {
      "epoch": 0.38478104809763103,
      "grad_norm": 0.25247758626937866,
      "learning_rate": 4.5575601374570445e-05,
      "loss": 7.4162,
      "step": 1340
    },
    {
      "epoch": 0.38765254845656855,
      "grad_norm": 0.11271294206380844,
      "learning_rate": 4.514604810996564e-05,
      "loss": 7.4171,
      "step": 1350
    },
    {
      "epoch": 0.3905240488155061,
      "grad_norm": 0.2194310873746872,
      "learning_rate": 4.471649484536083e-05,
      "loss": 7.4091,
      "step": 1360
    },
    {
      "epoch": 0.39339554917444364,
      "grad_norm": 0.07860855013132095,
      "learning_rate": 4.4286941580756014e-05,
      "loss": 7.4215,
      "step": 1370
    },
    {
      "epoch": 0.3962670495333812,
      "grad_norm": 0.15196599066257477,
      "learning_rate": 4.3857388316151204e-05,
      "loss": 7.4112,
      "step": 1380
    },
    {
      "epoch": 0.39913854989231873,
      "grad_norm": 0.07066044211387634,
      "learning_rate": 4.3427835051546394e-05,
      "loss": 7.4209,
      "step": 1390
    },
    {
      "epoch": 0.4020100502512563,
      "grad_norm": 0.1532115787267685,
      "learning_rate": 4.299828178694158e-05,
      "loss": 7.4196,
      "step": 1400
    },
    {
      "epoch": 0.4020100502512563,
      "eval_loss": 7.411787033081055,
      "eval_runtime": 297.3957,
      "eval_samples_per_second": 0.673,
      "eval_steps_per_second": 0.168,
      "step": 1400
    },
    {
      "epoch": 0.4048815506101938,
      "grad_norm": 0.0875985398888588,
      "learning_rate": 4.256872852233677e-05,
      "loss": 7.4134,
      "step": 1410
    },
    {
      "epoch": 0.4077530509691314,
      "grad_norm": 0.1244080513715744,
      "learning_rate": 4.213917525773196e-05,
      "loss": 7.4177,
      "step": 1420
    },
    {
      "epoch": 0.4106245513280689,
      "grad_norm": 0.22392809391021729,
      "learning_rate": 4.170962199312715e-05,
      "loss": 7.4191,
      "step": 1430
    },
    {
      "epoch": 0.4134960516870065,
      "grad_norm": 0.08054130524396896,
      "learning_rate": 4.1280068728522335e-05,
      "loss": 7.4114,
      "step": 1440
    },
    {
      "epoch": 0.416367552045944,
      "grad_norm": 0.07821539044380188,
      "learning_rate": 4.0850515463917525e-05,
      "loss": 7.4163,
      "step": 1450
    },
    {
      "epoch": 0.4192390524048816,
      "grad_norm": 0.1586633324623108,
      "learning_rate": 4.0420962199312715e-05,
      "loss": 7.4134,
      "step": 1460
    },
    {
      "epoch": 0.4221105527638191,
      "grad_norm": 0.16833949089050293,
      "learning_rate": 3.999140893470791e-05,
      "loss": 7.4112,
      "step": 1470
    },
    {
      "epoch": 0.42498205312275666,
      "grad_norm": 0.18823520839214325,
      "learning_rate": 3.9561855670103094e-05,
      "loss": 7.4329,
      "step": 1480
    },
    {
      "epoch": 0.4278535534816942,
      "grad_norm": 0.14027120172977448,
      "learning_rate": 3.9132302405498284e-05,
      "loss": 7.4198,
      "step": 1490
    },
    {
      "epoch": 0.43072505384063176,
      "grad_norm": 0.12433597445487976,
      "learning_rate": 3.8702749140893474e-05,
      "loss": 7.4157,
      "step": 1500
    },
    {
      "epoch": 0.4335965541995693,
      "grad_norm": 0.1623368114233017,
      "learning_rate": 3.8273195876288657e-05,
      "loss": 7.4191,
      "step": 1510
    },
    {
      "epoch": 0.43646805455850685,
      "grad_norm": 0.12086217850446701,
      "learning_rate": 3.7843642611683846e-05,
      "loss": 7.421,
      "step": 1520
    },
    {
      "epoch": 0.43933955491744436,
      "grad_norm": 0.09792816638946533,
      "learning_rate": 3.741408934707904e-05,
      "loss": 7.4055,
      "step": 1530
    },
    {
      "epoch": 0.44221105527638194,
      "grad_norm": 0.13646799325942993,
      "learning_rate": 3.698453608247423e-05,
      "loss": 7.4106,
      "step": 1540
    },
    {
      "epoch": 0.44508255563531945,
      "grad_norm": 0.20401036739349365,
      "learning_rate": 3.6554982817869415e-05,
      "loss": 7.4107,
      "step": 1550
    },
    {
      "epoch": 0.44795405599425697,
      "grad_norm": 1.0068244934082031,
      "learning_rate": 3.6125429553264605e-05,
      "loss": 7.4149,
      "step": 1560
    },
    {
      "epoch": 0.45082555635319455,
      "grad_norm": 0.180192232131958,
      "learning_rate": 3.5695876288659795e-05,
      "loss": 7.416,
      "step": 1570
    },
    {
      "epoch": 0.45369705671213206,
      "grad_norm": 0.2341671884059906,
      "learning_rate": 3.5266323024054985e-05,
      "loss": 7.4234,
      "step": 1580
    },
    {
      "epoch": 0.45656855707106964,
      "grad_norm": 0.1952623724937439,
      "learning_rate": 3.4836769759450174e-05,
      "loss": 7.4119,
      "step": 1590
    },
    {
      "epoch": 0.45944005743000715,
      "grad_norm": 0.1268448531627655,
      "learning_rate": 3.4407216494845364e-05,
      "loss": 7.4136,
      "step": 1600
    },
    {
      "epoch": 0.45944005743000715,
      "eval_loss": 7.408841609954834,
      "eval_runtime": 296.7166,
      "eval_samples_per_second": 0.674,
      "eval_steps_per_second": 0.169,
      "step": 1600
    },
    {
      "epoch": 0.4623115577889447,
      "grad_norm": 0.20880593359470367,
      "learning_rate": 3.3977663230240554e-05,
      "loss": 7.4227,
      "step": 1610
    },
    {
      "epoch": 0.46518305814788224,
      "grad_norm": 0.1578226089477539,
      "learning_rate": 3.354810996563574e-05,
      "loss": 7.422,
      "step": 1620
    },
    {
      "epoch": 0.4680545585068198,
      "grad_norm": 0.13610397279262543,
      "learning_rate": 3.3118556701030926e-05,
      "loss": 7.4086,
      "step": 1630
    },
    {
      "epoch": 0.47092605886575734,
      "grad_norm": 0.2077338546514511,
      "learning_rate": 3.2689003436426116e-05,
      "loss": 7.4239,
      "step": 1640
    },
    {
      "epoch": 0.4737975592246949,
      "grad_norm": 0.18658293783664703,
      "learning_rate": 3.225945017182131e-05,
      "loss": 7.4131,
      "step": 1650
    },
    {
      "epoch": 0.4766690595836324,
      "grad_norm": 0.08543404936790466,
      "learning_rate": 3.1829896907216496e-05,
      "loss": 7.4146,
      "step": 1660
    },
    {
      "epoch": 0.47954055994257,
      "grad_norm": 0.1326826512813568,
      "learning_rate": 3.1400343642611685e-05,
      "loss": 7.4187,
      "step": 1670
    },
    {
      "epoch": 0.4824120603015075,
      "grad_norm": 0.10787282884120941,
      "learning_rate": 3.0970790378006875e-05,
      "loss": 7.4107,
      "step": 1680
    },
    {
      "epoch": 0.4852835606604451,
      "grad_norm": 0.11137022078037262,
      "learning_rate": 3.0541237113402065e-05,
      "loss": 7.4069,
      "step": 1690
    },
    {
      "epoch": 0.4881550610193826,
      "grad_norm": 0.28060272336006165,
      "learning_rate": 3.011168384879725e-05,
      "loss": 7.4119,
      "step": 1700
    },
    {
      "epoch": 0.4910265613783202,
      "grad_norm": 0.34186604619026184,
      "learning_rate": 2.968213058419244e-05,
      "loss": 7.4165,
      "step": 1710
    },
    {
      "epoch": 0.4938980617372577,
      "grad_norm": 0.22613853216171265,
      "learning_rate": 2.925257731958763e-05,
      "loss": 7.4152,
      "step": 1720
    },
    {
      "epoch": 0.49676956209619527,
      "grad_norm": 0.14928314089775085,
      "learning_rate": 2.8823024054982817e-05,
      "loss": 7.4191,
      "step": 1730
    },
    {
      "epoch": 0.4996410624551328,
      "grad_norm": 0.11886584013700485,
      "learning_rate": 2.8393470790378007e-05,
      "loss": 7.4171,
      "step": 1740
    },
    {
      "epoch": 0.5025125628140703,
      "grad_norm": 0.08728177845478058,
      "learning_rate": 2.7963917525773196e-05,
      "loss": 7.4084,
      "step": 1750
    },
    {
      "epoch": 0.5053840631730079,
      "grad_norm": 0.17870302498340607,
      "learning_rate": 2.753436426116839e-05,
      "loss": 7.4151,
      "step": 1760
    },
    {
      "epoch": 0.5082555635319455,
      "grad_norm": 0.19536346197128296,
      "learning_rate": 2.7104810996563572e-05,
      "loss": 7.4147,
      "step": 1770
    },
    {
      "epoch": 0.511127063890883,
      "grad_norm": 0.25724682211875916,
      "learning_rate": 2.6675257731958765e-05,
      "loss": 7.4144,
      "step": 1780
    },
    {
      "epoch": 0.5139985642498205,
      "grad_norm": 0.12526822090148926,
      "learning_rate": 2.6245704467353955e-05,
      "loss": 7.4077,
      "step": 1790
    },
    {
      "epoch": 0.5168700646087581,
      "grad_norm": 0.12590034306049347,
      "learning_rate": 2.5816151202749145e-05,
      "loss": 7.4059,
      "step": 1800
    },
    {
      "epoch": 0.5168700646087581,
      "eval_loss": 7.400999546051025,
      "eval_runtime": 298.1513,
      "eval_samples_per_second": 0.671,
      "eval_steps_per_second": 0.168,
      "step": 1800
    }
  ],
  "logging_steps": 10,
  "max_steps": 2400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.674187288689541e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
